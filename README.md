# ted-talk-RAG
TED Talk RAG Assistant

In the file `embeding_RAG_tuning.ipynb` you can find everything implmented to acreate the embedings for ted talks, the upserting to the pinecone index and creating overline the rag flow (architecture). I run few manuak grid searches and evaluations. The final indexing that worked the best is subitted with fully indexed `ted_talks_en.csv` file.


Overall to run the `app.py` create virtual python enviroment `.venv` (it's recommended) and run this line to install the dependencies: 
```bash
pip install -r requirements.txt
```

Note: The final  selected RAG hyperparameters are:
- chunk_size = 758 (smaller chunk size more precision for smaller details)
- overlap_ratio = 0.1 (smaller overlap)
- top_k = 20 (but much higher k retrieved docs)

To run the `embeding_RAG_tuning.ipynb` heavier dependencies are neded (I put them in different file), Run this line:
```bash
pip install -r heavier_requirements.txt
```

This repo is **Deployed at Vercel!**, to test the returined results run these commands: 
```bash
curl "https://ted-talk-rag-psi.vercel.app/api/stats"
```

Returns json showing the final hyperparameters:
```json
{
  "chunk_size": 758,
  "overlap_ratio": 0.1,
  "top_k": 20
}

```
To query the RAG System: 

```bash
curl -i -X POST "https://ted-talk-mm1gk1493-barbaras-projects-2418128d.vercel.app/api/prompt" \
  -H "Content-Type: application/json" \
  -d "{\"question\":\"What is the talk about education and creativity?\"}"
```
Retuns json: 

```json
{
  "response": "Final natural language answer generated by the model.",
  "context": [
    {
      "talk_id": "66",
      "title": "Do Schools Kill Creativity?",
      "chunk": "Transcript passage retrieved from Pinecone...",
      "score": 0.5571
    }
  ],
  "Augmented_prompt": {
    "System": "System prompt used for grounding the model",
    "User": "User prompt including retrieved context"
  }
}

```
