{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ca4fdb",
   "metadata": {},
   "source": [
    "# *Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2574a87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, math, time, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d029a",
   "metadata": {},
   "source": [
    "# *Configurations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5181ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.llmod.ai/v1\"  \n",
    "EMBED_MODEL = \"RPRTHPB-text-embedding-3-small\"\n",
    "EMBED_DIMS = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33d02a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking restrictions\n",
    "MAX_TOKENS = 2048\n",
    "MAX_OVERLAP_RATIO = 0.30\n",
    "\n",
    "# Heuristic since we may not have a tokenizer:\n",
    "# rough token ≈ word * 1.3, so max_words ~ MAX_TOKENS / 1.3\n",
    "MAX_WORDS = int(MAX_TOKENS / 1.3)\n",
    "OVERLAP_WORDS = int(MAX_WORDS * MAX_OVERLAP_RATIO)\n",
    "\n",
    "# Budget-safe dev: start small, then scale up\n",
    "START_WITH_N_TALKS = 5  # set None to do all later\n",
    "\n",
    "# Output artifact files (cached embeddings)\n",
    "OUT_META_JSONL = \"ted_chunks_meta.jsonl\"\n",
    "OUT_EMB_NPY = \"ted_chunks_embeds.npy\"\n",
    "OUT_IDMAP_JSON = \"ted_chunks_idmap.json\"  # to avoid duplicates across runs\n",
    "\n",
    "# API key\n",
    "LLMOD_API_KEY = os.getenv(\"LLMOD_API_KEY\")  # or paste here: \"sk-....\"\n",
    "if not LLMOD_API_KEY:\n",
    "    raise ValueError(\"Set env var LLMOD_API_KEY or paste it into LLMOD_API_KEY.\")\n",
    "\n",
    "HEADERS = {\"Authorization\": f\"Bearer {LLMOD_API_KEY}\", \"Content-Type\": \"application/json\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349404ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# PINECONE_ENV = os.getenv(\"PINECONE_ENV\") or \"us-east-1\"  # example\n",
    "INDEX_NAME = \"ted\"\n",
    "\n",
    "EMBED_DIMS = 1536\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b25833",
   "metadata": {},
   "source": [
    "# *Chunks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2242c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_hash(text: str) -> str:\n",
    "    return hashlib.sha256(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def approx_word_chunks(text: str, max_words: int, overlap_words: int):\n",
    "    \"\"\"\n",
    "    Word-based chunker to approximate token limits.\n",
    "    Ensures overlap <= 30% by construction if overlap_words <= 0.3*max_words.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    step = max_words - overlap_words\n",
    "    if step <= 0:\n",
    "        raise ValueError(\"overlap_words too large; step must be > 0.\")\n",
    "\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(start + max_words, len(words))\n",
    "        chunk_words = words[start:end]\n",
    "        chunk_text = \" \".join(chunk_words).strip()\n",
    "        if chunk_text:\n",
    "            chunks.append(chunk_text)\n",
    "        if end == len(words):\n",
    "            break\n",
    "        start += step\n",
    "    return chunks\n",
    "\n",
    "def embed_texts_batch(texts, model=EMBED_MODEL, dims=EMBED_DIMS, max_retries=6):\n",
    "    \"\"\"\n",
    "    Calls llmod.ai embeddings endpoint (OpenAI-compatible).\n",
    "    Uses exponential backoff on transient errors.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/embeddings\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"input\": texts,\n",
    "        \"dimensions\": dims,  # keep aligned with the model default (1536)\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = requests.post(url, headers=HEADERS, data=json.dumps(payload), timeout=60)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                # OpenAI-style: data[\"data\"] is list of {embedding: [...]}\n",
    "                embs = [np.array(item[\"embedding\"], dtype=np.float32) for item in data[\"data\"]]\n",
    "                return np.vstack(embs)\n",
    "            # Retry on rate limit / transient server issues\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                sleep_s = min(2 ** attempt, 30)\n",
    "                time.sleep(sleep_s)\n",
    "                continue\n",
    "            # Otherwise: hard fail with details\n",
    "            raise RuntimeError(f\"Embeddings error {r.status_code}: {r.text[:500]}\")\n",
    "        except requests.RequestException as e:\n",
    "            sleep_s = min(2 ** attempt, 30)\n",
    "            time.sleep(sleep_s)\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Embeddings failed after retries. Last error: {last_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92b41a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['talk_id', 'title', 'speaker_1', 'all_speakers', 'occupations',\n",
       "       'about_speakers', 'views', 'recorded_date', 'published_date', 'event',\n",
       "       'native_lang', 'available_lang', 'comments', 'duration', 'topics',\n",
       "       'related_talks', 'url', 'description', 'transcript'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Load the dataset CSV\n",
    "# If your dataset is large, consider reading only needed columns first.\n",
    "# Example assumes you already have it locally as ted.csv:\n",
    "CSV_PATH = \"ted_talks_en.csv\"  # <-- change this\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Optional: start small for budget\n",
    "if START_WITH_N_TALKS is not None:\n",
    "    df = df.head(START_WITH_N_TALKS).copy()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34574701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, dict_keys(['chunk_uid', 'talk_id', 'title', 'chunk_id', 'text']))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Build chunk records (metadata + text)\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    talk_id = str(row.get(\"talk_id\", \"\"))\n",
    "    title = str(row.get(\"title\", \"\"))\n",
    "    transcript = str(row.get(\"transcript\", \"\") or \"\")\n",
    "    if not transcript.strip():\n",
    "        continue\n",
    "\n",
    "    chunks = approx_word_chunks(transcript, max_words=MAX_WORDS, overlap_words=OVERLAP_WORDS)\n",
    "\n",
    "    for ci, chunk_text in enumerate(chunks):\n",
    "        chunk_uid = stable_hash(talk_id + \"|\" + title + \"|\" + str(ci) + \"|\" + chunk_text)\n",
    "        records.append({\n",
    "            \"chunk_uid\": chunk_uid,\n",
    "            \"talk_id\": talk_id,\n",
    "            \"title\": title,\n",
    "            \"chunk_id\": ci,\n",
    "            \"text\": chunk_text,\n",
    "        })\n",
    "\n",
    "len(records), records[0].keys() if records else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ecd023d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 0\n",
      "Already embedded: 0\n",
      "To embed now: 0\n"
     ]
    }
   ],
   "source": [
    "# 3) Load previous cache (so we don't re-embed)\n",
    "if os.path.exists(OUT_IDMAP_JSON):\n",
    "    with open(OUT_IDMAP_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        seen = set(json.load(f))\n",
    "else:\n",
    "    seen = set()\n",
    "\n",
    "new_records = [r for r in records if r[\"chunk_uid\"] not in seen]\n",
    "print(\"Total records:\", len(records))\n",
    "print(\"Already embedded:\", len(records) - len(new_records))\n",
    "print(\"To embed now:\", len(new_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6439a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Embeddings shape: (14, 1536)\n",
      "Saved: ted_chunks_embeds.npy ted_chunks_meta.jsonl ted_chunks_idmap.json\n"
     ]
    }
   ],
   "source": [
    "# 4) Embed new chunks in batches + append to cache\n",
    "BATCH_SIZE = 64  # you can tune; smaller batches can be safer\n",
    "\n",
    "# Load existing embeddings if present\n",
    "if os.path.exists(OUT_EMB_NPY):\n",
    "    old_embs = np.load(OUT_EMB_NPY)\n",
    "else:\n",
    "    old_embs = None\n",
    "\n",
    "new_emb_list = []\n",
    "to_write_meta = []\n",
    "\n",
    "for i in range(0, len(new_records), BATCH_SIZE):\n",
    "    batch = new_records[i:i+BATCH_SIZE]\n",
    "    texts = [b[\"text\"] for b in batch]\n",
    "    embs = embed_texts_batch(texts)\n",
    "\n",
    "    # Sanity check dimensions\n",
    "    if embs.shape[1] != EMBED_DIMS:\n",
    "        raise ValueError(f\"Unexpected embedding dims: {embs.shape[1]} (expected {EMBED_DIMS})\")\n",
    "\n",
    "    new_emb_list.append(embs)\n",
    "    to_write_meta.extend(batch)\n",
    "\n",
    "    print(f\"Embedded {min(i+BATCH_SIZE, len(new_records))}/{len(new_records)}\")\n",
    "\n",
    "# Append embeddings\n",
    "if new_emb_list:\n",
    "    new_embs = np.vstack(new_emb_list)\n",
    "    all_embs = new_embs if old_embs is None else np.vstack([old_embs, new_embs])\n",
    "else:\n",
    "    all_embs = old_embs if old_embs is not None else np.zeros((0, EMBED_DIMS), dtype=np.float32)\n",
    "\n",
    "# Save embeddings matrix\n",
    "np.save(OUT_EMB_NPY, all_embs)\n",
    "\n",
    "# Append metadata (jsonl)\n",
    "if to_write_meta:\n",
    "    with open(OUT_META_JSONL, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in to_write_meta:\n",
    "            f.write(json.dumps({\n",
    "                \"chunk_uid\": r[\"chunk_uid\"],\n",
    "                \"talk_id\": r[\"talk_id\"],\n",
    "                \"title\": r[\"title\"],\n",
    "                \"chunk_id\": r[\"chunk_id\"],\n",
    "                \"text\": r[\"text\"],\n",
    "            }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Update seen set and save\n",
    "for r in to_write_meta:\n",
    "    seen.add(r[\"chunk_uid\"])\n",
    "with open(OUT_IDMAP_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sorted(list(seen)), f)\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"Embeddings shape:\", all_embs.shape)\n",
    "print(\"Saved:\", OUT_EMB_NPY, OUT_META_JSONL, OUT_IDMAP_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d3627",
   "metadata": {},
   "source": [
    "# Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53417c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: ted\n"
     ]
    }
   ],
   "source": [
    "existing = [idx[\"name\"] for idx in pc.list_indexes()]\n",
    "\n",
    "if INDEX_NAME not in existing:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=EMBED_DIMS,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(\"Ready:\", INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b067294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings: (14, 1536)\n",
      "Loaded meta rows: 14\n",
      "Already upserted IDs (local cache): 0\n",
      "To upsert now: 14\n",
      "Upserted 14/14\n",
      "✅ Upsert complete.\n",
      "Local upsert cache saved to: pinecone_upserted_ids.json\n",
      "Index stats: {'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
      "                                    'content-length': '184',\n",
      "                                    'content-type': 'application/json',\n",
      "                                    'date': 'Fri, 26 Dec 2025 22:47:39 GMT',\n",
      "                                    'grpc-status': '0',\n",
      "                                    'server': 'envoy',\n",
      "                                    'x-envoy-upstream-service-time': '91',\n",
      "                                    'x-pinecone-request-id': '1732630235628279066',\n",
      "                                    'x-pinecone-request-latency-ms': '91',\n",
      "                                    'x-pinecone-response-duration-ms': '93'}},\n",
      " 'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'memoryFullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'__default__': {'vector_count': 14}},\n",
      " 'storageFullness': 0.0,\n",
      " 'total_vector_count': 14,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# ====== CONTINUE HERE: Upsert cached vectors into Pinecone ======\n",
    "\n",
    "OUT_PINECONE_IDMAP_JSON = \"pinecone_upserted_ids.json\"\n",
    "\n",
    "# Load cached embeddings\n",
    "if not os.path.exists(OUT_EMB_NPY):\n",
    "    raise FileNotFoundError(f\"Missing embeddings file: {OUT_EMB_NPY}\")\n",
    "embs = np.load(OUT_EMB_NPY)\n",
    "\n",
    "# Load cached metadata jsonl (must be same order as embeddings were appended)\n",
    "if not os.path.exists(OUT_META_JSONL):\n",
    "    raise FileNotFoundError(f\"Missing metadata file: {OUT_META_JSONL}\")\n",
    "\n",
    "meta_rows = []\n",
    "with open(OUT_META_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            meta_rows.append(json.loads(line))\n",
    "\n",
    "if len(meta_rows) != embs.shape[0]:\n",
    "    raise ValueError(\n",
    "        f\"Mismatch: meta rows={len(meta_rows)} vs embeddings={embs.shape[0]}. \"\n",
    "        \"These must be aligned (same append order).\"\n",
    "    )\n",
    "\n",
    "print(\"Loaded embeddings:\", embs.shape)\n",
    "print(\"Loaded meta rows:\", len(meta_rows))\n",
    "\n",
    "# Load already-upserted ids (local cache to avoid re-upserting)\n",
    "if os.path.exists(OUT_PINECONE_IDMAP_JSON):\n",
    "    with open(OUT_PINECONE_IDMAP_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        upserted = set(json.load(f))\n",
    "else:\n",
    "    upserted = set()\n",
    "\n",
    "print(\"Already upserted IDs (local cache):\", len(upserted))\n",
    "\n",
    "def safe_metadata(m: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Pinecone metadata must be JSON-serializable, typically simple types.\n",
    "    Also keep text size reasonable (metadata size limits exist).\n",
    "    \"\"\"\n",
    "    text = m.get(\"text\", \"\") or \"\"\n",
    "    # Keep a snippet to avoid oversized metadata; adjust if you want.\n",
    "    text_snippet = text[:2000]\n",
    "\n",
    "    return {\n",
    "        \"talk_id\": str(m.get(\"talk_id\", \"\")),\n",
    "        \"title\": str(m.get(\"title\", \"\")),\n",
    "        \"chunk_id\": int(m.get(\"chunk_id\", 0)),\n",
    "        \"text\": text_snippet,\n",
    "    }\n",
    "\n",
    "# Build items to upsert (skip already upserted IDs)\n",
    "items = []\n",
    "for i, m in enumerate(meta_rows):\n",
    "    _id = m[\"chunk_uid\"]\n",
    "    if _id in upserted:\n",
    "        continue\n",
    "\n",
    "    vec = embs[i]\n",
    "    if vec.shape[0] != EMBED_DIMS:\n",
    "        raise ValueError(f\"Bad dims at row {i}: got {vec.shape[0]} expected {EMBED_DIMS}\")\n",
    "\n",
    "    items.append((_id, vec.tolist(), safe_metadata(m)))\n",
    "\n",
    "print(\"To upsert now:\", len(items))\n",
    "\n",
    "# Upsert in batches\n",
    "UPSERT_BATCH = 100  # safe default; you can set 50 if you prefer\n",
    "for start in range(0, len(items), UPSERT_BATCH):\n",
    "    batch = items[start:start+UPSERT_BATCH]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "    # update local cache\n",
    "    for _id, _, _ in batch:\n",
    "        upserted.add(_id)\n",
    "\n",
    "    if (start // UPSERT_BATCH) % 5 == 0:\n",
    "        print(f\"Upserted {min(start+UPSERT_BATCH, len(items))}/{len(items)}\")\n",
    "\n",
    "# Persist local upsert cache\n",
    "with open(OUT_PINECONE_IDMAP_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sorted(list(upserted)), f)\n",
    "\n",
    "print(\"✅ Upsert complete.\")\n",
    "print(\"Local upsert cache saved to:\", OUT_PINECONE_IDMAP_JSON)\n",
    "\n",
    "# Optional: quick sanity check by describing index stats\n",
    "try:\n",
    "    stats = index.describe_index_stats()\n",
    "    print(\"Index stats:\", stats)\n",
    "except Exception as e:\n",
    "    print(\"describe_index_stats failed (non-fatal):\", repr(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
