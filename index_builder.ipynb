{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ca4fdb",
   "metadata": {},
   "source": [
    "# *Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2574a87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, math, time, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import textwrap\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d029a",
   "metadata": {},
   "source": [
    "# *Configurations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d02a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking restrictions\n",
    "MAX_TOKENS = 1024 # [512, 1024, 2048]\n",
    "MAX_OVERLAP_RATIO = 0.2 # [0.05, 0.15, 0.25]\n",
    "EMBED_DIMS = 1536\n",
    "\n",
    "OVERLAP_WORDS = int(MAX_TOKENS * MAX_OVERLAP_RATIO)\n",
    "START_WITH_N_TALKS = 30  # set None to do all data\n",
    "\n",
    "# Output artifact files (cached embeddings)\n",
    "OUT_META_JSONL = \"ted_chunks_meta.jsonl\"\n",
    "OUT_EMB_NPY = \"ted_chunks_embeds.npy\"\n",
    "OUT_IDMAP_JSON = \"ted_chunks_idmap.json\"  # to avoid duplicates across runs\n",
    "\n",
    "# API keys\n",
    "LLMOD_API_KEY = os.getenv(\"LLMOD_API_KEY\")  # or paste here: \"sk-....\"\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX_NAME = \"ted\"\n",
    "\n",
    "HEADERS = {\"Authorization\": f\"Bearer {LLMOD_API_KEY}\", \"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac46f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMOD API settings\n",
    "BASE_URL = \"https://api.llmod.ai/v1\"  \n",
    "EMBED_MODEL = \"RPRTHPB-text-embedding-3-small\"\n",
    "EMBED_DIMS = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e1bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== RAG parameters ======\n",
    "CHAT_MODEL = \"RPRTHPB-gpt-5-mini\"\n",
    "\n",
    "# Must choose & report (per assignment)\n",
    "RAG_CHUNK_SIZE_TOKENS = MAX_TOKENS          # 2048 (max allowed)\n",
    "RAG_OVERLAP_RATIO = MAX_OVERLAP_RATIO       # 0.30 (max allowed)\n",
    "RAG_TOP_K = 2                               # <= 30 (tune: 5-12 often good)\n",
    "\n",
    "RETRIEVE_INCLUDE_TEXT = True  # we stored snippet in metadata[\"text\"]\n",
    "\n",
    "REQUIRED_SYSTEM_PROMPT = \"\"\"You are a TED Talk assistant that answers questions strictly and\n",
    "only based on the TED dataset context provided to you (metadata\n",
    "and transcript passages). You must not use any external\n",
    "knowledge, the open internet, or information that is not explicitly\n",
    "contained in the retrieved context. If the answer cannot be\n",
    "determined from the provided context, respond: “I don't know\n",
    "based on the provided TED data.” Always explain your answer\n",
    "using the given context, quoting or paraphrasing the relevant\n",
    "transcript or metadata when helpful.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b25833",
   "metadata": {},
   "source": [
    "# *Chunks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2242c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_hash(text: str) -> str:\n",
    "    return hashlib.sha256(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def approx_word_chunks(text: str, max_words: int, overlap_words: int):\n",
    "    \"\"\"\n",
    "    Word-based chunker to approximate token limits.\n",
    "    Ensures overlap <= 30% by construction if overlap_words <= 0.3*max_words.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    step = max_words - overlap_words\n",
    "    if step <= 0:\n",
    "        raise ValueError(\"overlap_words too large; step must be > 0.\")\n",
    "\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(start + max_words, len(words))\n",
    "        chunk_words = words[start:end]\n",
    "        chunk_text = \" \".join(chunk_words).strip()\n",
    "        if chunk_text:\n",
    "            chunks.append(chunk_text)\n",
    "        if end == len(words):\n",
    "            break\n",
    "        start += step\n",
    "    return chunks\n",
    "\n",
    "def embed_texts_batch(texts, model=EMBED_MODEL, dims=EMBED_DIMS, max_retries=6):\n",
    "    \"\"\"\n",
    "    Calls llmod.ai embeddings endpoint (OpenAI-compatible).\n",
    "    Uses exponential backoff on transient errors.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/embeddings\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"input\": texts,\n",
    "        \"dimensions\": dims,  # aligned with the model default (1536)\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = requests.post(url, headers=HEADERS, data=json.dumps(payload), timeout=60)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                # data[\"data\"] is list of {embedding: [...]}\n",
    "                embs = [np.array(item[\"embedding\"], dtype=np.float32) for item in data[\"data\"]]\n",
    "                return np.vstack(embs)\n",
    "            # Retry on rate limit\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                sleep_s = min(2 ** attempt, 30)\n",
    "                time.sleep(sleep_s)\n",
    "                continue\n",
    "            # fails + explnation\n",
    "            raise RuntimeError(f\"Embeddings error {r.status_code}: {r.text[:500]}\")\n",
    "        except requests.RequestException as e:\n",
    "            sleep_s = min(2 ** attempt, 30)\n",
    "            time.sleep(sleep_s)\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Embeddings failed after retries. Last error: {last_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f92b41a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker_1</th>\n",
       "      <th>all_speakers</th>\n",
       "      <th>occupations</th>\n",
       "      <th>about_speakers</th>\n",
       "      <th>views</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>event</th>\n",
       "      <th>native_lang</th>\n",
       "      <th>available_lang</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>topics</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>{0: 'Al Gore'}</td>\n",
       "      <td>{0: ['climate advocate']}</td>\n",
       "      <td>{0: 'Nobel Laureate Al Gore focused the world’...</td>\n",
       "      <td>3523392</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa...</td>\n",
       "      <td>272.0</td>\n",
       "      <td>977</td>\n",
       "      <td>['alternative energy', 'cars', 'climate change...</td>\n",
       "      <td>{243: 'New thinking on the climate crisis', 54...</td>\n",
       "      <td>https://www.ted.com/talks/al_gore_averting_the...</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>{0: 'Hans Rosling'}</td>\n",
       "      <td>{0: ['global health expert; data visionary']}</td>\n",
       "      <td>{0: 'In Hans Rosling’s hands, data sings. Glob...</td>\n",
       "      <td>14501685</td>\n",
       "      <td>2006-02-22</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'az', 'bg', 'bn', 'bs', 'cs', 'da', 'de...</td>\n",
       "      <td>628.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>['Africa', 'Asia', 'Google', 'demo', 'economic...</td>\n",
       "      <td>{2056: \"Own your body's data\", 2296: 'A visual...</td>\n",
       "      <td>https://www.ted.com/talks/hans_rosling_the_bes...</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>{0: 'David Pogue'}</td>\n",
       "      <td>{0: ['technology columnist']}</td>\n",
       "      <td>{0: 'David Pogue is the personal technology co...</td>\n",
       "      <td>1920832</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'de', 'el', 'en', 'es', 'fa', 'fr...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1286</td>\n",
       "      <td>['computers', 'entertainment', 'interface desi...</td>\n",
       "      <td>{1725: '10 top time-saving tech tips', 2274: '...</td>\n",
       "      <td>https://www.ted.com/talks/david_pogue_simplici...</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>{0: 'Majora Carter'}</td>\n",
       "      <td>{0: ['activist for environmental justice']}</td>\n",
       "      <td>{0: 'Majora Carter redefined the field of envi...</td>\n",
       "      <td>2664069</td>\n",
       "      <td>2006-02-26</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['ar', 'bg', 'bn', 'ca', 'cs', 'de', 'en', 'es...</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1116</td>\n",
       "      <td>['MacArthur grant', 'activism', 'business', 'c...</td>\n",
       "      <td>{1041: '3 stories of local eco-entrepreneurshi...</td>\n",
       "      <td>https://www.ted.com/talks/majora_carter_greeni...</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>Sir Ken Robinson</td>\n",
       "      <td>{0: 'Sir Ken Robinson'}</td>\n",
       "      <td>{0: ['author', 'educator']}</td>\n",
       "      <td>{0: \"Creativity expert Sir Ken Robinson challe...</td>\n",
       "      <td>65051954</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>en</td>\n",
       "      <td>['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'cs...</td>\n",
       "      <td>4931.0</td>\n",
       "      <td>1164</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>{865: 'Bring on the learning revolution!', 173...</td>\n",
       "      <td>https://www.ted.com/talks/sir_ken_robinson_do_...</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>Good morning. How are you? (Audience) Good. It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   talk_id                            title         speaker_1  \\\n",
       "0        1      Averting the climate crisis           Al Gore   \n",
       "1       92  The best stats you've ever seen      Hans Rosling   \n",
       "2        7                 Simplicity sells       David Pogue   \n",
       "3       53              Greening the ghetto     Majora Carter   \n",
       "4       66      Do schools kill creativity?  Sir Ken Robinson   \n",
       "\n",
       "              all_speakers                                    occupations  \\\n",
       "0           {0: 'Al Gore'}                      {0: ['climate advocate']}   \n",
       "1      {0: 'Hans Rosling'}  {0: ['global health expert; data visionary']}   \n",
       "2       {0: 'David Pogue'}                  {0: ['technology columnist']}   \n",
       "3     {0: 'Majora Carter'}    {0: ['activist for environmental justice']}   \n",
       "4  {0: 'Sir Ken Robinson'}                    {0: ['author', 'educator']}   \n",
       "\n",
       "                                      about_speakers     views recorded_date  \\\n",
       "0  {0: 'Nobel Laureate Al Gore focused the world’...   3523392    2006-02-25   \n",
       "1  {0: 'In Hans Rosling’s hands, data sings. Glob...  14501685    2006-02-22   \n",
       "2  {0: 'David Pogue is the personal technology co...   1920832    2006-02-24   \n",
       "3  {0: 'Majora Carter redefined the field of envi...   2664069    2006-02-26   \n",
       "4  {0: \"Creativity expert Sir Ken Robinson challe...  65051954    2006-02-25   \n",
       "\n",
       "  published_date    event native_lang  \\\n",
       "0     2006-06-27  TED2006          en   \n",
       "1     2006-06-27  TED2006          en   \n",
       "2     2006-06-27  TED2006          en   \n",
       "3     2006-06-27  TED2006          en   \n",
       "4     2006-06-27  TED2006          en   \n",
       "\n",
       "                                      available_lang  comments  duration  \\\n",
       "0  ['ar', 'bg', 'cs', 'de', 'el', 'en', 'es', 'fa...     272.0       977   \n",
       "1  ['ar', 'az', 'bg', 'bn', 'bs', 'cs', 'da', 'de...     628.0      1190   \n",
       "2  ['ar', 'bg', 'de', 'el', 'en', 'es', 'fa', 'fr...     124.0      1286   \n",
       "3  ['ar', 'bg', 'bn', 'ca', 'cs', 'de', 'en', 'es...     219.0      1116   \n",
       "4  ['af', 'ar', 'az', 'be', 'bg', 'bn', 'ca', 'cs...    4931.0      1164   \n",
       "\n",
       "                                              topics  \\\n",
       "0  ['alternative energy', 'cars', 'climate change...   \n",
       "1  ['Africa', 'Asia', 'Google', 'demo', 'economic...   \n",
       "2  ['computers', 'entertainment', 'interface desi...   \n",
       "3  ['MacArthur grant', 'activism', 'business', 'c...   \n",
       "4  ['children', 'creativity', 'culture', 'dance',...   \n",
       "\n",
       "                                       related_talks  \\\n",
       "0  {243: 'New thinking on the climate crisis', 54...   \n",
       "1  {2056: \"Own your body's data\", 2296: 'A visual...   \n",
       "2  {1725: '10 top time-saving tech tips', 2274: '...   \n",
       "3  {1041: '3 stories of local eco-entrepreneurshi...   \n",
       "4  {865: 'Bring on the learning revolution!', 173...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.ted.com/talks/al_gore_averting_the...   \n",
       "1  https://www.ted.com/talks/hans_rosling_the_bes...   \n",
       "2  https://www.ted.com/talks/david_pogue_simplici...   \n",
       "3  https://www.ted.com/talks/majora_carter_greeni...   \n",
       "4  https://www.ted.com/talks/sir_ken_robinson_do_...   \n",
       "\n",
       "                                         description  \\\n",
       "0  With the same humor and humanity he exuded in ...   \n",
       "1  You've never seen data presented like this. Wi...   \n",
       "2  New York Times columnist David Pogue takes aim...   \n",
       "3  In an emotionally charged talk, MacArthur-winn...   \n",
       "4  Sir Ken Robinson makes an entertaining and pro...   \n",
       "\n",
       "                                          transcript  \n",
       "0  Thank you so much, Chris. And it's truly a gre...  \n",
       "1  About 10 years ago, I took on the task to teac...  \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...  \n",
       "3  If you're here today — and I'm very happy that...  \n",
       "4  Good morning. How are you? (Audience) Good. It...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_PATH = \"ted_talks_en.csv\"  \n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# start small for budget\n",
    "if START_WITH_N_TALKS is not None:\n",
    "    df = df.head(START_WITH_N_TALKS).copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34574701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, dict_keys(['chunk_uid', 'talk_id', 'title', 'chunk_id', 'text']))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build chunk records (metadata + text)\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    talk_id = str(row.get(\"talk_id\", \"\"))\n",
    "    title = str(row.get(\"title\", \"\"))\n",
    "    transcript = str(row.get(\"transcript\", \"\") or \"\")\n",
    "    if not transcript.strip():\n",
    "        continue\n",
    "\n",
    "    chunks = approx_word_chunks(transcript, max_words=MAX_TOKENS, overlap_words=OVERLAP_WORDS)\n",
    "\n",
    "    for ci, chunk_text in enumerate(chunks):\n",
    "        chunk_uid = stable_hash(talk_id + \"|\" + title + \"|\" + str(ci) + \"|\" + chunk_text)\n",
    "        records.append({\n",
    "            \"chunk_uid\": chunk_uid,\n",
    "            \"talk_id\": talk_id,\n",
    "            \"title\": title,\n",
    "            \"chunk_id\": ci,\n",
    "            \"text\": chunk_text,\n",
    "        })\n",
    "\n",
    "len(records), records[0].keys() if records else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ecd023d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 118\n",
      "Already embedded: 118\n",
      "To embed now: 0\n"
     ]
    }
   ],
   "source": [
    "# Load previous cache (so we don't re-embed)\n",
    "if os.path.exists(OUT_IDMAP_JSON):\n",
    "    with open(OUT_IDMAP_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        seen = set(json.load(f))\n",
    "else:\n",
    "    seen = set()\n",
    "\n",
    "new_records = [r for r in records if r[\"chunk_uid\"] not in seen]\n",
    "print(\"Total records:\", len(records))\n",
    "print(\"Already embedded:\", len(records) - len(new_records))\n",
    "print(\"To embed now:\", len(new_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6439a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Embeddings shape: (157, 1536)\n",
      "Saved: ted_chunks_embeds.npy ted_chunks_meta.jsonl ted_chunks_idmap.json\n"
     ]
    }
   ],
   "source": [
    "# Embed new chunks in batches + append to cache\n",
    "BATCH_SIZE = 64 \n",
    "\n",
    "if os.path.exists(OUT_EMB_NPY):\n",
    "    old_embs = np.load(OUT_EMB_NPY)\n",
    "else:\n",
    "    old_embs = None\n",
    "\n",
    "new_emb_list = []\n",
    "to_write_meta = []\n",
    "\n",
    "for i in range(0, len(new_records), BATCH_SIZE):\n",
    "    batch = new_records[i:i+BATCH_SIZE]\n",
    "    texts = [b[\"text\"] for b in batch]\n",
    "    embs = embed_texts_batch(texts)\n",
    "    # Sanity check dimensions\n",
    "    if embs.shape[1] != EMBED_DIMS:\n",
    "        raise ValueError(f\"Unexpected embedding dims: {embs.shape[1]} (expected {EMBED_DIMS})\")\n",
    "\n",
    "    new_emb_list.append(embs)\n",
    "    to_write_meta.extend(batch)\n",
    "\n",
    "    print(f\"Embedded {min(i+BATCH_SIZE, len(new_records))}/{len(new_records)}\")\n",
    "\n",
    "# Append embeddings\n",
    "if new_emb_list:\n",
    "    new_embs = np.vstack(new_emb_list)\n",
    "    all_embs = new_embs if old_embs is None else np.vstack([old_embs, new_embs])\n",
    "else:\n",
    "    all_embs = old_embs if old_embs is not None else np.zeros((0, EMBED_DIMS), dtype=np.float32)\n",
    "\n",
    "# Save embeddings matrix\n",
    "np.save(OUT_EMB_NPY, all_embs)\n",
    "\n",
    "# Append metadata (jsonl)\n",
    "if to_write_meta:\n",
    "    with open(OUT_META_JSONL, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in to_write_meta:\n",
    "            f.write(json.dumps({\n",
    "                \"chunk_uid\": r[\"chunk_uid\"],\n",
    "                \"talk_id\": r[\"talk_id\"],\n",
    "                \"title\": r[\"title\"],\n",
    "                \"chunk_id\": r[\"chunk_id\"],\n",
    "                \"text\": r[\"text\"],\n",
    "            }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Update seen set and save\n",
    "for r in to_write_meta:\n",
    "    seen.add(r[\"chunk_uid\"])\n",
    "with open(OUT_IDMAP_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sorted(list(seen)), f)\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"Embeddings shape:\", all_embs.shape)\n",
    "print(\"Saved:\", OUT_EMB_NPY, OUT_META_JSONL, OUT_IDMAP_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d3627",
   "metadata": {},
   "source": [
    "# Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b53417c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: ted\n"
     ]
    }
   ],
   "source": [
    "existing = [idx[\"name\"] for idx in pc.list_indexes()]\n",
    "\n",
    "if INDEX_NAME not in existing:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=EMBED_DIMS, # using the dimensions returned by embedding model\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(\"Ready:\", INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b067294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings: (157, 1536)\n",
      "Loaded meta rows: 157\n",
      "Already upserted IDs (local cache): 39\n",
      "To upsert now: 118\n",
      "Upserted 100/118\n",
      "✅ Upsert complete.\n",
      "Local upsert cache saved to: pinecone_upserted_ids.json\n",
      "Index stats: {'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
      "                                    'content-length': '186',\n",
      "                                    'content-type': 'application/json',\n",
      "                                    'date': 'Sun, 28 Dec 2025 13:36:00 GMT',\n",
      "                                    'grpc-status': '0',\n",
      "                                    'server': 'envoy',\n",
      "                                    'x-envoy-upstream-service-time': '33',\n",
      "                                    'x-pinecone-request-id': '7029018262805765821',\n",
      "                                    'x-pinecone-request-latency-ms': '33',\n",
      "                                    'x-pinecone-response-duration-ms': '35'}},\n",
      " 'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'memoryFullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'__default__': {'vector_count': 157}},\n",
      " 'storageFullness': 0.0,\n",
      " 'total_vector_count': 157,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "OUT_PINECONE_IDMAP_JSON = \"pinecone_upserted_ids.json\"\n",
    "\n",
    "if not os.path.exists(OUT_EMB_NPY):\n",
    "    raise FileNotFoundError(f\"Missing embeddings file: {OUT_EMB_NPY}\")\n",
    "embs = np.load(OUT_EMB_NPY)\n",
    "\n",
    "if not os.path.exists(OUT_META_JSONL):\n",
    "    raise FileNotFoundError(f\"Missing metadata file: {OUT_META_JSONL}\")\n",
    "\n",
    "meta_rows = []\n",
    "with open(OUT_META_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            meta_rows.append(json.loads(line))\n",
    "\n",
    "if len(meta_rows) != embs.shape[0]:\n",
    "    raise ValueError(\n",
    "        f\"Mismatch: meta rows={len(meta_rows)} vs embeddings={embs.shape[0]}. \"\n",
    "        \"These must be aligned (same append order).\"\n",
    "    )\n",
    "print(\"Loaded embeddings:\", embs.shape)\n",
    "print(\"Loaded meta rows:\", len(meta_rows))\n",
    "\n",
    "# using local cache to avoid re-upserting\n",
    "if os.path.exists(OUT_PINECONE_IDMAP_JSON):\n",
    "    with open(OUT_PINECONE_IDMAP_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        upserted = set(json.load(f))\n",
    "else:\n",
    "    upserted = set()\n",
    "\n",
    "print(\"Already upserted IDs (local cache):\", len(upserted))\n",
    "\n",
    "def safe_metadata(m: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Pinecone metadata must be JSON-serializable, typically simple types.\n",
    "    Also keep text size reasonable (metadata size limits exist).\n",
    "    \"\"\"\n",
    "    text = m.get(\"text\", \"\") or \"\"\n",
    "    # Keep a snippet to avoid oversized metadata; adjust if you want.\n",
    "    text_snippet = text[:2000]\n",
    "\n",
    "    return {\n",
    "        \"talk_id\": str(m.get(\"talk_id\", \"\")),\n",
    "        \"title\": str(m.get(\"title\", \"\")),\n",
    "        \"chunk_id\": int(m.get(\"chunk_id\", 0)),\n",
    "        \"text\": text_snippet,\n",
    "    }\n",
    "\n",
    "# Build items to upsert (skip already upserted IDs)\n",
    "items = []\n",
    "for i, m in enumerate(meta_rows):\n",
    "    _id = m[\"chunk_uid\"]\n",
    "    if _id in upserted:\n",
    "        continue\n",
    "\n",
    "    vec = embs[i]\n",
    "    if vec.shape[0] != EMBED_DIMS:\n",
    "        raise ValueError(f\"Bad dims at row {i}: got {vec.shape[0]} expected {EMBED_DIMS}\")\n",
    "\n",
    "    items.append((_id, vec.tolist(), safe_metadata(m)))\n",
    "\n",
    "print(\"To upsert now:\", len(items))\n",
    "\n",
    "# Upsert in batches\n",
    "UPSERT_BATCH = 100\n",
    "for start in range(0, len(items), UPSERT_BATCH):\n",
    "    batch = items[start:start+UPSERT_BATCH]\n",
    "    index.upsert(vectors=batch)\n",
    "    # update local cache\n",
    "    for _id, _, _ in batch:\n",
    "        upserted.add(_id)\n",
    "\n",
    "    if (start // UPSERT_BATCH) % 5 == 0:\n",
    "        print(f\"Upserted {min(start+UPSERT_BATCH, len(items))}/{len(items)}\")\n",
    "\n",
    "# Persist local upsert cache\n",
    "with open(OUT_PINECONE_IDMAP_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sorted(list(upserted)), f)\n",
    "\n",
    "print(\"✅ Upsert complete.\")\n",
    "print(\"Local upsert cache saved to:\", OUT_PINECONE_IDMAP_JSON)\n",
    "\n",
    "# describing index stats\n",
    "stats = index.describe_index_stats()\n",
    "print(\"Index stats:\", stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08ef9a",
   "metadata": {},
   "source": [
    "# Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd9e4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_query(text: str) -> np.ndarray:\n",
    "    \"\"\"Embed one query text -> (1536,) float32\"\"\"\n",
    "    emb = embed_texts_batch([text], model=EMBED_MODEL, dims=EMBED_DIMS)\n",
    "    if emb.shape != (1, EMBED_DIMS):\n",
    "        raise ValueError(f\"Bad query embedding shape: {emb.shape}\")\n",
    "    return emb[0].astype(np.float32)\n",
    "\n",
    "def retrieve_from_pinecone(query: str, top_k: int = RAG_TOP_K):\n",
    "    \"\"\"\n",
    "    Returns list of matches with fields: id, score, metadata.\n",
    "    \"\"\"\n",
    "    qvec = embed_query(query)\n",
    "    res = index.query(\n",
    "        vector=qvec.tolist(),\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    # normalizing the dict object returned by the pinecone:\n",
    "    matches = res.get(\"matches\", res[\"matches\"]) if isinstance(res, dict) else res.matches\n",
    "    # print(\"Returned from PINECONE: \\n\", matches)\n",
    "    out = []\n",
    "    for m in matches:\n",
    "        mid = m.get(\"id\", None) if isinstance(m, dict) else m.id\n",
    "        score = m.get(\"score\", None) if isinstance(m, dict) else m.score\n",
    "        meta = m.get(\"metadata\", {}) if isinstance(m, dict) else (m.metadata or {})\n",
    "        out.append({\"id\": mid, \"score\": float(score) if score is not None else None, \"metadata\": meta})\n",
    "    return out\n",
    "\n",
    "def build_context(matches, max_chars: int = 12000) -> str:\n",
    "    \"\"\"\n",
    "    Build a compact context block from retrieved matches.\n",
    "    We cap total chars to avoid bloating the model context (efficiency).\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    total = 0\n",
    "\n",
    "    for rank, item in enumerate(matches, start=1):\n",
    "        md = item[\"metadata\"] or {}\n",
    "        title = str(md.get(\"title\", \"\"))\n",
    "        talk_id = str(md.get(\"talk_id\", \"\"))\n",
    "        chunk_id = md.get(\"chunk_id\", \"\")\n",
    "        text = str(md.get(\"text\", \"\")) if RETRIEVE_INCLUDE_TEXT else \"\"\n",
    "\n",
    "        block = (\n",
    "            f\"[{rank}] talk_id={talk_id} | title={title} | chunk_id={chunk_id} | score={item['score']:.4f}\\n\"\n",
    "            f\"PASSAGE:\\n{text}\\n\"\n",
    "        )\n",
    "        if total + len(block) > max_chars:\n",
    "            break\n",
    "        parts.append(block)\n",
    "        total += len(block)\n",
    "\n",
    "    return \"\\n---\\n\".join(parts).strip()\n",
    "\n",
    "def print_retrieved(matches, text_chars: int = 400):\n",
    "    print(\"\\n=== RETRIEVED MATCHES ===\")\n",
    "    for i, m in enumerate(matches, start=1):\n",
    "        md = m.get(\"metadata\", {}) or {}\n",
    "        title = md.get(\"title\", \"\")\n",
    "        talk_id = md.get(\"talk_id\", \"\")\n",
    "        chunk_id = md.get(\"chunk_id\", \"\")\n",
    "        score = m.get(\"score\", None)\n",
    "\n",
    "        passage = (md.get(\"text\", \"\") or \"\")\n",
    "        passage = passage[:text_chars] + (\"...\" if len(passage) > text_chars else \"\")\n",
    "\n",
    "        print(f\"\\n[{i}] score={score:.4f} | talk_id={talk_id} | chunk_id={chunk_id} | title={title}\")\n",
    "        print(\"PASSAGE:\", passage)\n",
    "\n",
    "\n",
    "def call_chat_model(question: str, context: str) -> str:\n",
    "    \"\"\"\n",
    "    Calls llmod.ai chat completions endpoint.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/chat/completions\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": REQUIRED_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"TED DATA CONTEXT:\\n{context}\\n\\nQUESTION:\\n{question}\"},\n",
    "    ]\n",
    "    payload = {\n",
    "        \"model\": CHAT_MODEL,\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    # minimal retry\n",
    "    max_retries = 6\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = requests.post(url, headers=HEADERS, data=json.dumps(payload), timeout=90)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                time.sleep(min(2 ** attempt, 30))\n",
    "                continue\n",
    "            raise RuntimeError(f\"Chat error {r.status_code}: {r.text[:500]}\")\n",
    "        except requests.RequestException as e:\n",
    "            last_err = e\n",
    "            time.sleep(min(2 ** attempt, 30))\n",
    "    raise RuntimeError(f\"Chat failed after retries. Last error: {last_err}\")\n",
    "\n",
    "def rag_answer(question: str, top_k: int = RAG_TOP_K, min_matches: int = 1, debug: bool = True):\n",
    "    \"\"\"\n",
    "    End-to-end RAG: retrieve -> build context -> ask model.\n",
    "    \"\"\"\n",
    "    matches = retrieve_from_pinecone(question, top_k=top_k)\n",
    "    if debug:\n",
    "        print(f\"Retrieved: {len(matches)} matches (top_k={top_k})\")\n",
    "        print_retrieved(matches, text_chars=600)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Retrieved: {len(matches)} matches (top_k={top_k})\")\n",
    "\n",
    "    if len(matches) < min_matches:\n",
    "        return \"I don’t know based on the provided TED data.\"\n",
    "\n",
    "    context = build_context(matches)\n",
    "    if debug:\n",
    "        print(\"\\nContext preview (first 600 chars):\")\n",
    "        print(context[:600] + (\"...\" if len(context) > 600 else \"\"))\n",
    "        print(\"\\n---\\nRAG hyperparameters to report:\")\n",
    "        print(f\"chunk_size_tokens={RAG_CHUNK_SIZE_TOKENS}, overlap_ratio={RAG_OVERLAP_RATIO}, top_k={top_k}\")\n",
    "\n",
    "    answer = call_chat_model(question, context)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9ed638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ====== QUICK TEST ======\n",
    "# q = \"What is the main message of the talk about education and creativity?\"\n",
    "# print(rag_answer(q, top_k=RAG_TOP_K, debug=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b56e1",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c173585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests...\n",
      "\n",
      "\n",
      "============================================================\n",
      "TEST 1: Precise Fact Retrieval\n",
      "QUESTION: In the talk about the 'birth of Wikipedia', how many employees does Jimmy Wales say were managing the site at the time of the recording?\n",
      "------------------------------------------------------------\n",
      "MODEL ANSWER:\n",
      "I don't know based on the provided TED data. The supplied transcript passages say Wikipedia was “managed by virtually an all‑volunteer staff” and note that “we actually hired [Brian]” after he worked part‑time and then full‑time, but none of the provided excerpts states how many paid employees were managing the site at the time. For example: “everything about Wikipedia is managed by virtually an all‑volunteer staff” and “we actually hired him,” but no total employee number is given in the supplied passages.\n",
      "\n",
      "[Expected Logic/Hint]: Should mention a very small number (often cited as 'one' or a small group) or the specific role of volunteers.\n",
      "\n",
      "============================================================\n",
      "TEST 2: Multi-Result Topic Listing\n",
      "QUESTION: Which talks focus on the environment, climate change, or sustainable design? Return a list of exactly 3 talk titles.\n",
      "------------------------------------------------------------\n",
      "MODEL ANSWER:\n",
      "I don't know based on the provided TED data.\n",
      "\n",
      "The supplied TED passages all come from a single talk, titled \"Averting the climate crisis\" (talk_id=1). The transcript explicitly focuses on climate: for example, Al Gore says, \"I want to focus on what many of you have said you would like me to elaborate on: What can you do about the climate crisis?\" (chunk_id=1). Because only this one talk in the provided data addresses the environment/climate, I cannot produce a list of three such talks from the given TED dataset.\n",
      "\n",
      "[Expected Logic/Hint]: Likely candidates in first 30: 'Averting the climate crisis' (Al Gore), 'Greening the ghetto' (Majora Carter), 'Global warming's ruinous afterlife' (checking if in top 30) or other eco-focused talks.\n",
      "\n",
      "============================================================\n",
      "TEST 3: Key Idea Summary Extraction\n",
      "QUESTION: Find the talk by Tony Robbins. Provide the title and a short summary of his explanation for 'why we do what we do'.\n",
      "------------------------------------------------------------\n",
      "MODEL ANSWER:\n",
      "Title: \"A life of purpose\"\n",
      "\n",
      "Summary (based on the provided TED transcript): Robbins argues that much of what we do flows from a search for meaning — people feel \"spiritual emptiness\" and sense \"there's got to be more to life than this.\" He illustrates motivation with the story of Moses' staff, saying the staff \"represented three things about Moses' life\": identity (\"he was a shepherd\"), income (his assets were tied up in his flock), and influence (what you do with a shepherd's staff is \"you move sheep from point A to point B\"). In other words, our actions are shaped by who we think we are, what sustains us materially, and the influence we can exert.\n",
      "\n",
      "[Expected Logic/Hint]: Title: 'Why we do what we do'. Summary: Focuses on the 'six human needs' and the 'invisible forces' that drive behavior.\n",
      "\n",
      "============================================================\n",
      "TEST 4: Recommendation with Evidence-Based Justification\n",
      "QUESTION: I am interested in user interface design and how simplicity is better than complexity. Which talk should I watch?\n",
      "------------------------------------------------------------\n",
      "ERROR: Chat error 400: {\"error\":{\"message\":\"litellm.BadRequestError: litellm.ContentPolicyViolationError: litellm.ContentPolicyViolationError: AzureException - The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\\nmodel=RPRTHPB-gpt-5-mini. content_policy_fallback=None. fallbacks=None.\\n\\nSet 'content_policy_fal\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    # 1. Precise Fact Retrieval\n",
    "    {\n",
    "        \"category\": \"Precise Fact Retrieval\",\n",
    "        \"question\": \"In the talk about the 'birth of Wikipedia', how many employees does Jimmy Wales say were managing the site at the time of the recording?\",\n",
    "        \"expected_hint\": \"Should mention a very small number (often cited as 'one' or a small group) or the specific role of volunteers.\"\n",
    "    },\n",
    "    \n",
    "    # 2. Multi-Result Topic Listing (Up to 3 Results)\n",
    "    {\n",
    "        \"category\": \"Multi-Result Topic Listing\",\n",
    "        \"question\": \"Which talks focus on the environment, climate change, or sustainable design? Return a list of exactly 3 talk titles.\",\n",
    "        \"expected_hint\": \"Likely candidates in first 30: 'Averting the climate crisis' (Al Gore), 'Greening the ghetto' (Majora Carter), 'Global warming's ruinous afterlife' (checking if in top 30) or other eco-focused talks.\"\n",
    "    },\n",
    "\n",
    "    # 3. Key Idea Summary Extraction\n",
    "    {\n",
    "        \"category\": \"Key Idea Summary Extraction\",\n",
    "        \"question\": \"Find the talk by Tony Robbins. Provide the title and a short summary of his explanation for 'why we do what we do'.\",\n",
    "        \"expected_hint\": \"Title: 'Why we do what we do'. Summary: Focuses on the 'six human needs' and the 'invisible forces' that drive behavior.\"\n",
    "    },\n",
    "\n",
    "    # 4. Recommendation with Evidence-Based Justification\n",
    "    {\n",
    "        \"category\": \"Recommendation with Evidence-Based Justification\",\n",
    "        \"question\": \"I am interested in user interface design and how simplicity is better than complexity. Which talk should I watch?\",\n",
    "        \"expected_hint\": \"Recommendation: 'Simplicity sells' by David Pogue. Justification: Mentions his critique of software interfaces and the importance of simplicity in technology.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Running tests...\\n\")\n",
    "\n",
    "for i, test in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST {i}: {test['category']}\")\n",
    "    print(f\"QUESTION: {test['question']}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    try:\n",
    "        response = rag_answer(test['question'], top_k=3, debug=False)\n",
    "        \n",
    "        print(f\"MODEL ANSWER:\\n{response}\")\n",
    "        print(f\"\\n[Expected Logic/Hint]: {test['expected_hint']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15fcadfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ADDITIONAL tests ...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ADDITIONAL TEST 1: Precise Fact Retrieval\n",
      "QUESTION: In the talk 'The freakonomics of crack dealing', what does Steven Levitt say about the actual hourly wage of a street-corner crack dealer?\n",
      "------------------------------------------------------------\n",
      "MODEL ANSWER:\n",
      "I don't know based on the provided TED data.\n",
      "\n",
      "The supplied transcript excerpts describe Levitt's access to the gang's financial records, compare gang pay to McDonald's (saying \"the money looks about the same\"), and discuss compensating differentials and foot‑soldier pay, but none of the provided passages state the actual hourly wage figure for a street‑corner crack dealer. For example, chunk 0 notes he looked at \"the financial records of the gang,\" chunk 3 says \"the relationship to McDonald's breaks down here. The money looks about the same,\" and chunk 4 discusses pay adjustments in wartime, but no numeric hourly wage appears in the provided snippets.\n",
      "\n",
      "[Expected Logic/Hint]: He states it is very low, specifically 'below minimum wage' (or compares it to working at McDonald's).\n",
      "\n",
      "============================================================\n",
      "ADDITIONAL TEST 2: Multi-Result Topic Listing\n",
      "QUESTION: Which talks discuss 'happiness', 'psychology', or 'choice'? Return a list of exactly 3 talk titles.\n",
      "------------------------------------------------------------\n",
      "MODEL ANSWER:\n",
      "I don't know based on the provided TED data.\n",
      "\n",
      "The dataset you gave includes only one talk (talk_id=97, title \"The surprising science of happiness\"). That talk clearly discusses happiness, choice, and psychological experiments — for example the speaker describes \"people synthesizing happiness\" and gives newspaper examples (chunk 1: \"examples of people synthesizing happiness...\"), presents the \"free choice paradigm\" (chunk 2: \"a 50-year-old paradigm called the 'free choice paradigm'\"), and reports experiments with amnesia patients (chunk 2: \"We did this experiment with a group of patients who had anterograde amnesia...\"), but there are not three distinct talk titles in the provided TED data to return.\n",
      "\n",
      "[Expected Logic/Hint]: Should find titles like: 'The surprising science of happiness' (Dan Gilbert), 'The paradox of choice' (Barry Schwartz), 'Happiness in body and soul' (Eve Ensler), or 'Choice, happiness and spaghetti sauce' (Malcolm Gladwell).\n",
      "\n",
      "============================================================\n",
      "ADDITIONAL TEST 3: Key Idea Summary Extraction\n",
      "QUESTION: Find the talk by Malcolm Gladwell about spaghetti sauce. Provide the title and summarize his main conclusion about 'perfection' and 'choice'.\n",
      "------------------------------------------------------------\n",
      "MODEL ANSWER:\n",
      "Title: \"Choice, happiness and spaghetti sauce\"\n",
      "\n",
      "Summary: Gladwell uses the story of Howard Moskowitz (who made 45 varieties of spaghetti sauce) to argue that there is no single \"perfect\" product. As he quotes Moskowitz, \"There is no perfect pickle; there are only perfect pickles,\" and Moskowitz told Campbell's, \"You don't just need to improve your regular; you need to create zesty.\" Gladwell's main point is that people have distinct, legitimate taste segments (what he calls \"horizontal segmentation\"), and that asking consumers what they want often fails because \"the mind knows not what the tongue wants.\" The takeaway: instead of searching for one perfect item, companies should offer a range of options to match different people's preferences.\n",
      "\n",
      "[Expected Logic/Hint]: Title: 'Choice, happiness and spaghetti sauce'. Summary: The key idea is that there is no single perfect product for everyone, but rather 'perfect swarms' or segments (horizontal segmentation).\n",
      "\n",
      "============================================================\n",
      "ADDITIONAL TEST 4: Recommendation with Evidence-Based Justification\n",
      "QUESTION: I am interested in architecture and want to see a deep dive into the design process of a specific building. Which talk would you recommend?\n",
      "------------------------------------------------------------\n",
      "MODEL ANSWER:\n",
      "I recommend the talk \"Behind the design of Seattle's library\" (talk_id=49). The speaker takes a close, process-oriented look at a single building: describing how they \"re-digest[ed]\" the program, won \"the right to go back to first principles,\" recombined the program into a literal diagram of square footage, and organized the building into five efficiency \"platforms\" with in-between zones for unpredictable uses. The talk also frames the work as a \"hyper-rational process\" (one of three core ideas) and introduces the design strategy they call \"compartmentalized flexibility.\" Those quotes and details come directly from the transcript passages provided.\n",
      "\n",
      "[Expected Logic/Hint]: Recommendation: 'Behind the design of Seattle's library' by Joshua Prince-Ramus. Justification: He gives a tour of the Seattle Central Library and explains the hyper-rational design process.\n"
     ]
    }
   ],
   "source": [
    "additional_questions = [\n",
    "    {\n",
    "        \"category\": \"Precise Fact Retrieval\",\n",
    "        \"question\": \"In the talk 'The freakonomics of crack dealing', what does Steven Levitt say about the actual hourly wage of a street-corner crack dealer?\",\n",
    "        \"expected_hint\": \"He states it is very low, specifically 'below minimum wage' (or compares it to working at McDonald's).\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Multi-Result Topic Listing\",\n",
    "        \"question\": \"Which talks discuss 'happiness', 'psychology', or 'choice'? Return a list of exactly 3 talk titles.\",\n",
    "        \"expected_hint\": \"Should find titles like: 'The surprising science of happiness' (Dan Gilbert), 'The paradox of choice' (Barry Schwartz), 'Happiness in body and soul' (Eve Ensler), or 'Choice, happiness and spaghetti sauce' (Malcolm Gladwell).\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Key Idea Summary Extraction\",\n",
    "        \"question\": \"Find the talk by Malcolm Gladwell about spaghetti sauce. Provide the title and summarize his main conclusion about 'perfection' and 'choice'.\",\n",
    "        \"expected_hint\": \"Title: 'Choice, happiness and spaghetti sauce'. Summary: The key idea is that there is no single perfect product for everyone, but rather 'perfect swarms' or segments (horizontal segmentation).\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Recommendation with Evidence-Based Justification\",\n",
    "        \"question\": \"I am interested in architecture and want to see a deep dive into the design process of a specific building. Which talk would you recommend?\",\n",
    "        \"expected_hint\": \"Recommendation: 'Behind the design of Seattle's library' by Joshua Prince-Ramus. Justification: He gives a tour of the Seattle Central Library and explains the hyper-rational design process.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Running ADDITIONAL tests ...\\n\")\n",
    "\n",
    "for i, test in enumerate(additional_questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ADDITIONAL TEST {i}: {test['category']}\")\n",
    "    print(f\"QUESTION: {test['question']}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    try:\n",
    "        response = rag_answer(test['question'], top_k=3, debug=False)\n",
    "        print(f\"MODEL ANSWER:\\n{response}\")\n",
    "        print(f\"\\n[Expected Logic/Hint]: {test['expected_hint']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
